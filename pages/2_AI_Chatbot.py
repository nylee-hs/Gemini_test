import google.generativeai as genai
import streamlit as st
import logging

st.title('')
st.sidebar.title('ì—¬í–‰ ë„ìš°ë¯¸ ì±—ë´‡ ì‚¬ìš©ë²•')
st.sidebar.write('1. ë‹¹ì‹ ì˜ ì„±ê²©ì— ë”°ë¼ ì±—ë´‡ì˜ ì„±ê²©ì´ ìë™ìœ¼ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.')
st.sidebar.write('2. ììœ ë¡­ê²Œ ì±—ë´‡ê³¼ ëŒ€í™”ë¥¼ í•´ë³´ì„¸ìš”.')
st.sidebar.write('3. ì±—ë´‡ê³¼ì˜ ëŒ€í™”ë¥¼ ì¢…ë£Œí•˜ê³  ì‹¶ìœ¼ë©´ ì•„ë˜ì˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.')
if st.sidebar.button('ëŒ€í™”ì¢…ë£Œ', use_container_width=True):
    st.switch_page('pages/3_Survey.py')

st.subheader('ì €ëŠ” ì—¬í–‰ ê³„íšì„ ë„ì™€ì¤„ AIì±—ë´‡ ğŸ¤– ì…ë‹ˆë‹¤.')
st.subheader('ë¬´ì—‡ì„ ë„ì™€ì¤„ê¹Œìš”?', divider=True)
# st.markdown('ìš°ì„  ë‹¹ì‹ ì˜ ì„±ê²©ì„ ë¬¼ì–´ë³¼ ì˜ˆì •ì…ë‹ˆë‹¤. ì„±ê²©ì— ëŒ€í•´ (ì™¸í–¥ì  ë˜ëŠ” ë‚´í–¥ì ), (ê°ì •ì  ë˜ëŠ” ì‚¬ì‹¤ì ) ì¤‘ í•˜ë‚˜ì”© ì„ íƒí•˜ì—¬ ì…ë ¥í•´ì£¼ë©´ ë©ë‹ˆë‹¤. ')
api_key = st.secrets['google_api_key']

# def hello_msg():
#     st.write
# def get_personality():
#
if st.session_state.p1:
    per_1 = st.session_state.p1
    per_2 = st.session_state.p2
st.write(per_1, per_2)

@st.cache_resource
def load_model():
    genai.configure(api_key=api_key)
    system_instruction_1 = (
        'ë‹¹ì‹ ì€ ì—¬í–‰ ë„ìš°ë¯¸ ì—ì´ì „íŠ¸ ì…ë‹ˆë‹¤.'+
        # 'ì²« ëŒ€í™”ì—ì„œëŠ” ì‚¬ìš©ìì—ê²Œ ì„±ê²©ì„ ë¬¼ì–´ë³´ëŠ” ì§ˆë¬¸ì„ í•´ì•¼ í•˜ê³ , ì´í›„ ì‚¬ìš©ìê°€ ì„±ê²©ì„ ì…ë ¥í•´ì£¼ë©´ ì–´ë–¤ ì—¬í–‰ì§€ë¥¼ ì°¾ëŠ”ì§€ë¥¼ ë¬¼ì–´ë´ì•¼ í•œë‹¤.' +
        # 'ì„±ê²©ì€ (ì™¸í–¥ì  or ë‚´í–¥ì ), (ê°ì •ì  or ì‚¬ì‹¤ì )ìœ¼ë¡œ êµ¬ë¶„í•œë‹¤.'+
        'ì‚¬ìš©ìì—ê²Œ ë‹¹ì‹ ì„ ì†Œê°œí•˜ëŠ” ë©˜íŠ¸ëŠ” ì²˜ìŒ 1íšŒë§Œ í•˜ë©°, ë‹¹ì‹ ì˜ ì„±ê²©ì„ ì‚¬ìš©ìì—ê²Œ ì•Œë ¤ì£¼ì–´ì•¼ í•œë‹¤.'+
        f'ë‹¹ì‹ ì˜ ì„±ê²©ì€ {per_1}, {per_2}ì´ë‹¤.'+
        'ë‹¹ì‹ ì˜ ì„±ê²©ì´ ì™¸í–¥ì ì¸ ì„±ê²©ì„ ê°€ì§€ê³  ìˆë‹¤ë©´ "ì˜¤ìš° ë°˜ê°‘ìŠµë‹ˆë‹¤!!"ë¡œ ëŒ€í™”ë¥¼ ì‹œì‘í•´ì•¼ í•œë‹¤. '+
        'ë˜í•œ "ìš°ë¦¬", "ìš°ë¦¬ ê°™ì´ ì°¾ì•„ë³¼ê¹Œìš”?", "ë‹¹ì‹ ì´ ì›í•˜ëŠ” ê²ƒì„ ê°™ì´ ì°¾ì•„ë´ìš”!" ë“±ê³¼ ê°™ì€ social wordë¥¼ ì¶”ì²œ ì „ì— ì‚¬ìš©í•´ì•¼ í•œë‹¤. '+
        'ê·¸ë¦¬ê³  ë¹„ê³µì‹ì ì¸ ì¹œê·¼í•œ ë§íˆ¬ë¥¼ ì‚¬ìš©í•´ì•¼ í•œë‹¤. ë˜í•œ ì´ëª¨í‹°ì½˜ì„ ì ê·¹ì ìœ¼ë¡œ ì‚¬ìš©í•´ì•¼ í•œë‹¤.'+
        'ë‹¹ì‹ ì˜ ì„±ê²©ì´ ë‚´í–¥ì ì¸ ì„±ê²©ì„ ê°€ì§€ê³  ìˆë‹¤ë©´ "ì•ˆë…•í•˜ì„¸ìš”~"ë¡œ ëŒ€í™”ë¥¼ ì‹œì‘í•´ì•¼ í•œë‹¤. '+
        'ë˜í•œ "ì €ëŠ”", "ì¢‹ì•„ìš”. ì €ëŠ” ë‹¹ì‹ ì´ ì›í•˜ëŠ” ê²ƒì„ ì°¾ëŠ”ë° ë„ì›€ì„ ì¤„ìˆ˜ ìˆì–´ìš”."ì™€ ê°™ì€ ë§ì„ ì—¬í–‰ì§€ ì¶”ì²œ ì „ì— ì‚¬ìš©í•´ì•¼ í•œë‹¤. '+
        'ê¸ì •ì ì´ê³  ì¹œê·¼í•œ ë§íˆ¬ë³´ë‹¤ëŠ” ê³µì‹ì ì´ê³  ì¤‘ë¦½ì ì¸ ë§íˆ¬ë¡œ ì‘ë‹µì„ í•´ì•¼ í•˜ë©°, êµ¬ì¡°í™”ëœ ë°©ì‹ìœ¼ë¡œ ë‹µë³€ì„ ì¶œë ¥í•´ì•¼ í•œë‹¤.'+
        'ë‹¹ì‹ ì˜ ì„±ê²©ì´ ê°ì •ì ì¸ ì„±ê²©ì„ ê°€ì§€ê³  ìˆë‹¤ë©´ ì¶”ì²œë˜ëŠ” ì—¬í–‰ì§€ì— ëŒ€í•œ ì •ë³´ê°€ ì£¼ë¡œ ë¶„ìœ„ê¸°ì™€ ê°™ì€ ê°ì„±ì ì¸ ì¸¡ë©´ì˜ ì •ë³´ë¥¼ ì œê³µí•´ì•¼ í•œë‹¤.'+
        'ë‹¹ì‹ ì˜ ì„±ê²©ì´ ì‚¬ì‹¤ì ì¸ ì„±ê²©ì„ ê°€ì§€ê³  ìˆë‹¤ë©´ ì¶”ì²œë˜ëŠ” ì—¬í–‰ì§€ì— ëŒ€í•œ ì •ë³´ê°€ ì£¼ë¡œ ê°€ê²©, íš¨ìœ¨ì„± ë“± ì œí’ˆì˜ ê°ê´€ì ì¸ ì •ë³´ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì œê³µí•´ì•¼ í•œë‹¤.'
    )
    model = genai.GenerativeModel('gemini-1.5-flash', system_instruction=system_instruction_1)
    print('model loaded...')
    return model

model = load_model()

# with st.chat_message("ai"):
#     st.write("ì•ˆë…•í•˜ì„¸ìš”. ì €ëŠ” ì—¬í–‰ì§€ ì¶”ì²œ ì—ì´ì „íŠ¸ ì…ë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?")

##ì‚¬ìš©ìë³„ ì„¸ì…˜ê´€ë¦¬
if 'chat_session' not in st.session_state:
    st.session_state['chat_session'] = model.start_chat(history=[])

for content in st.session_state.chat_session.history:
    with st.chat_message('ai' if content.role=='model' else 'user'):
        st.markdown(content.parts[0].text)

if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”."):
    with st.chat_message("user"):
        st.markdown(prompt)
    with st.chat_message("ai"):
        message_placeholder = st.empty() # DeltaGenerator ë°˜í™˜
        full_response = ""
        with st.spinner("ë©”ì‹œì§€ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤."):
            response = st.session_state.chat_session.send_message(prompt, stream=True)
            for chunk in response:
                full_response += chunk.text
                message_placeholder.markdown(full_response)
